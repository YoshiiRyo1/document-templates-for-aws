# 生成 AI (Generative AI)

> 生成 AI ワークロードを構築しない場合、本セクションはスキップしてください。

## ガバナンス・データ保護

| 質問                                                                         | 質問の意図                                                                                   | ご回答 |
| ---------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | ------ |
| 生成 AI（Generative AI）の利用に関するガバナンスポリシーはありますか？ | 生成 AI の利用には Responsible AI の観点からガバナンスが必要。利用可能なモデル、入出力データの取り扱い、ハルシネーション対策、バイアス防止の方針を確認する。<br />Amazon Bedrock Guardrails でコンテンツフィルタリング、PII マスキング、トピック制限を設定できる。<br />Automated Reasoning checks で最大 99% の精度でハルシネーションを検出し、事実確認を行える。 |        |
| 生成 AI に入力・出力するデータの保護方針はありますか？ | Amazon Bedrock ではユーザーデータがモデルトレーニングに使用されないことが保証されている。<br />VPC エンドポイント（PrivateLink）経由でアクセスし、データ経路を保護できる。<br />モデル呼び出しの入出力ログ（Invocation Logging）を S3 / CloudWatch Logs に保管し、監査証跡として活用する。<br />Guardrails の PII フィルターで機密データのマスキングも可能。 |        |

## セキュリティ

| 質問                                                                         | 質問の意図                                                                                   | ご回答 |
| ---------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | ------ |
| AI/ML ワークロード固有のセキュリティ対策は検討していますか？ | 生成 AI ワークロードにはプロンプトインジェクション、ジェイルブレイク、モデル抽出、データポイズニング等の固有の脅威がある。<br />Bedrock Guardrails でプロンプト攻撃防御、入出力のコンテンツフィルタリングを適用できる。<br />AgentCore Gateway Policy でエージェントのアクセス制御と認可を管理できる。<br />生成 AI アプリケーション向けの脅威モデリングを実施する。 |        |

## 運用・オブザーバビリティ

| 質問                                                                         | 質問の意図                                                                                   | ご回答 |
| ---------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | ------ |
| 生成 AI アプリケーション（Amazon Bedrock 等）の運用管理方針はありますか？ | 生成 AI アプリケーションには従来と異なる運用課題がある（モデルバージョン管理、プロンプト管理、ガードレール運用、コスト管理）。<br />Amazon Bedrock AgentCore でエージェントのデプロイ・スケーリング・オブザーバビリティを一元管理できる。<br />CloudWatch の生成 AI オブザーバビリティでレイテンシ、トークン使用量、エラー率を監視できる。<br />LangChain、LangGraph、CrewAI 等の OSS フレームワークにも対応。 |        |

## パフォーマンス・コスト

| 質問                                                                         | 質問の意図                                                                                   | ご回答 |
| ---------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | ------ |
| 生成 AI 推論（LLM 呼び出し）のパフォーマンス要件はありますか？<br />（Time to First Token / Tokens Per Second / End-to-End Latency） | 生成 AI アプリケーションでは従来の API レスポンスタイムに加え、TTFT（最初のトークンまでの時間）や TPS（1秒あたりのトークン生成速度）が重要な性能指標となる。<br />Amazon Bedrock のプロビジョンドスループットで安定した推論性能を確保できる。<br />モデル選択（大規模 vs 小規模、リージョン内 vs クロスリージョン推論）がレイテンシとコストに直結する。 |        |
| 生成 AI ワークロードのコスト管理方針はありますか？ | Amazon Bedrock はオンデマンド（入力/出力トークン課金）とプロビジョンドスループット（時間課金）の 2 モデルがある。<br />モデル選択（大規模 vs 小規模、Bedrock vs SageMaker）がコストに大きく影響する。<br />プロンプトキャッシング、バッチ推論でコスト最適化が可能。<br />IAM Identity Center のユーザー属性（部門、コストセンター等）ベースのコスト配分で AI 利用コストを組織単位で追跡できる。 |        |
| 生成 AI アプリケーションの品質評価・テスト方針はありますか？ | Amazon Bedrock の Model Evaluation で各モデルのタスク適合性を評価できる。<br />カスタム評価メトリクス（正確性、関連性、有害性、忠実性）を定義しベースラインテストを実施する。<br />Bedrock Guardrails の Automated Reasoning checks で出力の事実確認を自動化できる。<br />本番トラフィックの品質モニタリングと継続的な評価パイプラインの構築を検討する。 |        |
