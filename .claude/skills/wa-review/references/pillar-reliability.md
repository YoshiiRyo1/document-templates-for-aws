# 信頼性の柱 (Reliability Pillar)

## 1. 柱の概要

信頼性の柱は、ワークロードが意図した機能を正しく一貫して実行する能力を対象とする。
ワークロードのライフサイクル全体を通じて期待どおりに動作し続けることが求められる。
信頼性を実現するには、強固な基盤、回復力のあるアーキテクチャ、一貫した変更管理、実証済みの障害復旧プロセスが必要となる。

AWS Well-Architected Framework における信頼性は、可用性 (Availability) と災害復旧 (Disaster Recovery) の両方を包含する。
可用性は一定期間における平均的な稼働率を示し、災害復旧は災害発生時の一回限りの復旧目標を定義する。
Recovery Time Objective (RTO) はサービス中断から復旧までの最大許容時間、Recovery Point Objective (RPO) は許容されるデータ損失の最大時間幅を意味する。

## 2. 設計原則

信頼性の柱では、以下の 5 つの設計原則を定義している。

### 障害から自動的に復旧する
ワークロードの主要業績評価指標 (KPI) を監視し、しきい値を超えた場合に自動化を実行する。
KPI は技術的な運用指標ではなく、ビジネス価値の指標とすべきである。

### 復旧手順をテストする
クラウドではワークロードの障害シナリオをテストし、復旧手順を検証できる。
自動化により障害をシミュレートし、過去の障害シナリオを再現して障害経路を事前に検証する。

### 水平方向にスケールしてワークロード全体の可用性を高める
大きなリソースを複数の小さなリソースに置き換え、単一障害の影響を軽減する。
リクエストを複数のリソースに分散し、共通の障害点を排除する。

### キャパシティの推測をやめる
クラウドでは需要とワークロードの使用率を監視し、リソースの追加・削除を自動化して最適なレベルを維持する。
Service Quotas の管理により制限を適切にコントロールする。

### オートメーションで変更を管理する
インフラストラクチャへの変更は自動化を通じて行うべきである。
自動化自体の変更も追跡・レビューの対象とする。

## 3. チェックポイント

### 基盤 (Foundations)

#### REL-1: Service Quotas と制約をどのように管理していますか
- すべての関連サービスについて Service Quotas を把握し、適切な引き上げ申請を行う。
- アカウントレベルおよびリソースレベルのクォータを監視し、しきい値に基づくアラートを設定する。
- AWS Trusted Advisor や Service Quotas コンソールを活用して定期的にクォータ使用状況を確認する。

#### REL-2: ネットワークトポロジをどのように計画していますか
- ワークロードのパブリックおよびプライベートの接続要件に対応するネットワークトポロジを設計する。
- IP アドレス空間を十分に確保し、将来の拡張を見据えた CIDR 設計を行う。
- Multi-AZ 構成を前提としたサブネット設計を実施する。

### ワークロードアーキテクチャ (Workload Architecture)

#### REL-3: ワークロードサービスアーキテクチャをどのように設計していますか
- サービス指向アーキテクチャ (SOA) またはマイクロサービスを採用し、障害の影響範囲を限定する。
- 各コンポーネントの障害がワークロード全体に波及しない設計とする。

#### REL-4: 障害を防止するための分散システムの相互作用をどのように設計していますか
- API コールにリトライとエクスポネンシャルバックオフを実装する。
- 冪等性を確保し、リトライ時の副作用を防止する。
- スロットリングを適用してリソースを保護する。

#### REL-5: 障害を緩和・耐えるための分散システムの相互作用をどのように設計していますか
- グレースフルデグラデーションを実装し、部分的な機能低下でサービスを継続する。
- サーキットブレーカーパターンを導入して障害の連鎖を防止する。
- 静的安定性を確保し、依存先が障害を起こしてもワークロードが動作し続ける設計とする。

### 変更管理 (Change Management)

#### REL-6: ワークロードリソースをどのように監視していますか
- Amazon CloudWatch によるメトリクス監視とアラームを設定する。
- ワークロードの各レイヤー（インフラ、アプリケーション、ビジネス）で適切な KPI を定義する。
- ヘルスチェックを実装し、異常を早期に検知する。

#### REL-7: 需要の変化に適応するようワークロードをどのように設計していますか
- Auto Scaling を適切に構成し、需要の変動に自動的に対応する。
- スケーリングポリシーにはターゲット追跡スケーリングの採用を検討する。
- 負荷テストによりスケーリング動作を事前に検証する。

#### REL-8: 変更をどのように実装していますか
- Infrastructure as Code (IaC) により環境変更を自動化・追跡する。
- デプロイメントパイプラインを構築し、変更のテストと段階的なロールアウトを実施する。
- ロールバック手順を整備し、問題発生時に迅速に復旧する。

### 障害管理 (Failure Management)

#### REL-9: データをどのようにバックアップしていますか
- すべての重要データについて自動バックアップを構成する。
- バックアップの保持期間を RPO に基づいて設定する。
- バックアップデータを異なるリージョンまたはアカウントに保管し、AWS Backup で一元管理する。

#### REL-10: 障害分離を活用してワークロードをどのように保護していますか
- Multi-AZ 配置により Availability Zone レベルの障害分離を実現する。
- マルチリージョン構成の必要性をビジネス要件に基づいて判断する。
- セルベースアーキテクチャやシャッフルシャーディングにより障害の影響範囲を制限する。

#### REL-11: コンポーネント障害に耐えるようワークロードをどのように設計していますか
- 単一障害点 (SPOF) を排除し、すべてのコンポーネントを冗長化する。
- ELB ヘルスチェックにより異常インスタンスを自動的にトラフィックから除外する。
- データベースには Multi-AZ 配置やリードレプリカを活用する。
- ステートレスなアーキテクチャを採用し、インスタンスの代替可能性を確保する。

#### REL-12: 信頼性をどのようにテストしていますか
- 障害注入テスト（カオスエンジニアリング）を定期的に実施する。
- AWS Fault Injection Service (FIS) を活用して制御された障害実験を行う。
- Game Day を実施し、チームの障害対応能力を検証する。

#### REL-13: 災害復旧 (DR) をどのように計画していますか
- ビジネス要件に基づいて RTO/RPO を明確に定義する。
- DR 戦略（Backup & Restore、Pilot Light、Warm Standby、Multi-Site Active/Active）を RTO/RPO に応じて選択する。
- DR 手順を文書化し、定期的にテストを実施する。
- フェイルオーバーとフェイルバックの手順を自動化する。

## 4. リポジトリとの対応関係

| チェックポイント | 対応するテンプレート |
| --- | --- |
| REL-1: Service Quotas の管理 | 該当なし（プロジェクト固有で確認） |
| REL-2: ネットワークトポロジ | cloud-design-network.md |
| REL-6: 監視 | cloud-design-monitoring.md |
| REL-7: Auto Scaling | cloud-design-availability.md |
| REL-9: バックアップ | cloud-design-backup.md |
| REL-10: 障害分離 (Multi-AZ) | cloud-design-availability.md, cloud-design-network.md |
| REL-11: コンポーネント障害耐性 | cloud-design-availability.md |
| REL-13: DR 計画 | cloud-design-backup.md |

## 5. よくある指摘事項

### Single-AZ 構成
本番ワークロードが単一の Availability Zone にのみ配置されており、AZ 障害時にサービス全体が停止するリスクがある。
EC2、RDS、ElastiCache 等のすべてのコンポーネントで Multi-AZ 構成を採用すべきである。

### バックアップの復元テスト未実施
バックアップを取得しているが、実際にリストアして正常にデータが復元できるか検証していない。
定期的にリストアテストを実施し、復旧手順の有効性を確認する必要がある。

### RPO/RTO が未定義
ビジネス要件に基づく RPO/RTO が明確に定義されておらず、適切な DR 戦略を選択できていない。
システムの重要度に応じて RPO/RTO を定量的に定義し、それに見合った DR 構成を設計すべきである。

### Auto Scaling 未設定
需要変動に対してリソースが固定されており、トラフィック急増時にサービス品質が低下するリスクがある。
Auto Scaling を構成し、CloudWatch メトリクスに基づくスケーリングポリシーを設定する。

### Service Quotas の確認・引き上げ未実施
デフォルトの Service Quotas のまま運用しており、ワークロードの成長に伴いクォータ上限に達するリスクがある。
事前にクォータを確認し、必要に応じて引き上げ申請を行う。

### ヘルスチェック未設定
ELB や Route 53 のヘルスチェックが適切に設定されておらず、異常なインスタンスにトラフィックが継続して送信される。
アプリケーションレベルのヘルスチェックを実装し、異常検知時に自動的にトラフィックを切り離す。

### 単一障害点の存在
NAT Gateway、踏み台サーバー、データベースなどが単一構成であり、障害時にシステム全体に影響する。
すべてのコンポーネントについて冗長構成を検討し、SPOF を排除する。

### 変更管理の自動化不足
インフラ変更が手動で実施されており、変更の追跡やロールバックが困難である。
IaC (CloudFormation, CDK, Terraform) を導入し、すべての変更をコード管理する。
